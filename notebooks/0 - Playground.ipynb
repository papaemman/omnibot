{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f1a22a2",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd12cad0",
   "metadata": {},
   "source": [
    "Generate Text: The most basic functionality an LLM has is just the ability to call it, passing in a string and getting back a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35987888",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOCAL .env file\n",
    "from dotenv import dotenv_values\n",
    "secrets = dotenv_values(\"../.env\")\n",
    "OPENAI_API_KEY = secrets['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead5a1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=1, n=2, best_of=2, openai_api_key=OPENAI_API_KEY)\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45bee62a",
   "metadata": {},
   "source": [
    "# DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabc5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0232a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generated': ['Message 1', 'Message 2', 'Message 3'],\n",
       " 'user': ['user 1', 'user 2']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = dict()\n",
    "history[\"generated\"] = [\"Message 1\", \"Message 2\", \"Message 3\"]\n",
    "history[\"user\"] = [\"user 1\", \"user 2\"]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c9b3775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conversation(history):\n",
    "    \"\"\"\n",
    "    Display conversation history using Streamlit messages.\n",
    "    - ChatBot\n",
    "    - User\n",
    "    \"\"\"\n",
    "    mixed_history = [item for pair in itertools.zip_longest(history[\"generated\"], history[\"user\"], fillvalue='') for item in pair  if item != '']\n",
    "\n",
    "    return mixed_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da11a435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Message 1', 'user 1', 'Message 2', 'user 2', 'Message 3']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_conversation(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnibot-lHmdBll9-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
